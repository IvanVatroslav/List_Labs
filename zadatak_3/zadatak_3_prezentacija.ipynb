{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ph text"
   ],
   "id": "a1d214745253b50a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:33:51.299549Z",
     "start_time": "2024-09-09T14:28:05.563020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%run zadatak_3.py"
   ],
   "id": "3007c20010a60cbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 33698, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936812\n",
      "[LightGBM] [Info] Start training from score -0.633420\n",
      "[LightGBM] [Info] Start training from score -1.123734\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633461\n",
      "[LightGBM] [Info] Start training from score -1.123628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633391\n",
      "[LightGBM] [Info] Start training from score -1.123742\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633391\n",
      "[LightGBM] [Info] Start training from score -1.123742\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26959, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936680\n",
      "[LightGBM] [Info] Start training from score -0.633428\n",
      "[LightGBM] [Info] Start training from score -1.123779\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26959, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936680\n",
      "[LightGBM] [Info] Start training from score -0.633428\n",
      "[LightGBM] [Info] Start training from score -1.123779\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 33698, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936812\n",
      "[LightGBM] [Info] Start training from score -0.633420\n",
      "[LightGBM] [Info] Start training from score -1.123734\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633461\n",
      "[LightGBM] [Info] Start training from score -1.123628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633391\n",
      "[LightGBM] [Info] Start training from score -1.123742\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633391\n",
      "[LightGBM] [Info] Start training from score -1.123742\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26959, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936680\n",
      "[LightGBM] [Info] Start training from score -0.633428\n",
      "[LightGBM] [Info] Start training from score -1.123779\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26959, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936680\n",
      "[LightGBM] [Info] Start training from score -0.633428\n",
      "[LightGBM] [Info] Start training from score -1.123779\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 33698, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936812\n",
      "[LightGBM] [Info] Start training from score -0.633420\n",
      "[LightGBM] [Info] Start training from score -1.123734\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633461\n",
      "[LightGBM] [Info] Start training from score -1.123628\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633391\n",
      "[LightGBM] [Info] Start training from score -1.123742\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26958, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936900\n",
      "[LightGBM] [Info] Start training from score -0.633391\n",
      "[LightGBM] [Info] Start training from score -1.123742\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26959, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936680\n",
      "[LightGBM] [Info] Start training from score -0.633428\n",
      "[LightGBM] [Info] Start training from score -1.123779\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 26959, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936680\n",
      "[LightGBM] [Info] Start training from score -0.633428\n",
      "[LightGBM] [Info] Start training from score -1.123779\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 28884, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936812\n",
      "[LightGBM] [Info] Start training from score -0.633476\n",
      "[LightGBM] [Info] Start training from score -1.123643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23108, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936606\n",
      "[LightGBM] [Info] Start training from score -0.633511\n",
      "[LightGBM] [Info] Start training from score -1.123677\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 28884, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936812\n",
      "[LightGBM] [Info] Start training from score -0.633476\n",
      "[LightGBM] [Info] Start training from score -1.123643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23108, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936606\n",
      "[LightGBM] [Info] Start training from score -0.633511\n",
      "[LightGBM] [Info] Start training from score -1.123677\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 28884, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936812\n",
      "[LightGBM] [Info] Start training from score -0.633476\n",
      "[LightGBM] [Info] Start training from score -1.123643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23107, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936863\n",
      "[LightGBM] [Info] Start training from score -0.633467\n",
      "[LightGBM] [Info] Start training from score -1.123634\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 23108, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.936606\n",
      "[LightGBM] [Info] Start training from score -0.633511\n",
      "[LightGBM] [Info] Start training from score -1.123677\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "ph text"
   ],
   "id": "4098144fe92986b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:02:42.861917Z",
     "start_time": "2024-09-09T19:02:41.342468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "cv_results_70_15_15 = pd.read_csv('results/cross_validation_multi_metric_results_70_15_15_split.csv')\n",
    "test_results_70_15_15 = pd.read_csv('results/final_test_results_70_15_15_split.csv')\n",
    "cv_results_60_20_20 = pd.read_csv('results/cross_validation_multi_metric_results_60_20_20_split.csv')\n",
    "test_results_60_20_20 = pd.read_csv('results/final_test_results_60_20_20_split.csv')\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:02:42.952675Z",
     "start_time": "2024-09-09T19:02:42.871891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv_results_70_15_15\n"
   ],
   "id": "dfe8b337a074dce7",
   "outputs": [
    {
     "data": {
      "text/plain": "                  Model Data Type  CV Accuracy  CV Accuracy Std  \\\n0                   KNN       Log     0.999228         0.000197   \n1                   KNN     Mixed     0.999228         0.000197   \n2                   KNN    Normal     0.999288         0.000173   \n3              LightGBM       Log     0.999288         0.000173   \n4              LightGBM     Mixed     0.999288         0.000173   \n5              LightGBM    Normal     0.999377         0.000145   \n6   Logistic Regression       Log     0.997121         0.000178   \n7   Logistic Regression     Mixed     0.997121         0.000178   \n8   Logistic Regression    Normal     0.997211         0.000059   \n9         Random Forest       Log     0.999021         0.000151   \n10        Random Forest     Mixed     0.999021         0.000151   \n11        Random Forest    Normal     0.999021         0.000151   \n12                  SVM       Log     0.998813         0.000248   \n13                  SVM     Mixed     0.998813         0.000248   \n14                  SVM    Normal     0.998932         0.000303   \n15              XGBoost       Log     0.999139         0.000197   \n16              XGBoost     Mixed     0.999139         0.000197   \n17              XGBoost    Normal     0.999139         0.000197   \n\n    CV F1 (Weighted)  CV F1 (Weighted) Std  CV F1 (Macro)  CV F1 (Macro) Std  \\\n0           0.999229              0.000197       0.998788           0.000362   \n1           0.999229              0.000197       0.998788           0.000362   \n2           0.999288              0.000173       0.998887           0.000303   \n3           0.999288              0.000173       0.998912           0.000307   \n4           0.999288              0.000173       0.998912           0.000307   \n5           0.999377              0.000145       0.999035           0.000317   \n6           0.997123              0.000178       0.995376           0.000372   \n7           0.997123              0.000178       0.995376           0.000372   \n8           0.997212              0.000061       0.995532           0.000159   \n9           0.999021              0.000151       0.998516           0.000323   \n10          0.999021              0.000151       0.998516           0.000323   \n11          0.999021              0.000151       0.998516           0.000323   \n12          0.998814              0.000248       0.998121           0.000533   \n13          0.998814              0.000248       0.998121           0.000533   \n14          0.998932              0.000302       0.998319           0.000614   \n15          0.999140              0.000196       0.998665           0.000369   \n16          0.999140              0.000196       0.998665           0.000369   \n17          0.999140              0.000196       0.998665           0.000369   \n\n    CV ROC AUC  CV ROC AUC Std  CV Precision  CV Precision Std  CV Recall  \\\n0     0.999999    2.545483e-07      0.999230          0.000196   0.999228   \n1     0.999999    2.545483e-07      0.999230          0.000196   0.999228   \n2     0.999915    1.029853e-04      0.999289          0.000172   0.999288   \n3     0.999997    2.016573e-06      0.999289          0.000172   0.999288   \n4     0.999997    2.016573e-06      0.999289          0.000172   0.999288   \n5     0.999996    4.776803e-06      0.999378          0.000145   0.999377   \n6     0.999942    1.564464e-05      0.997128          0.000180   0.997121   \n7     0.999942    1.564464e-05      0.997128          0.000180   0.997121   \n8     0.999936    1.952522e-05      0.997219          0.000065   0.997211   \n9     0.999997    1.354710e-06      0.999022          0.000150   0.999021   \n10    0.999997    1.354710e-06      0.999022          0.000150   0.999021   \n11    0.999997    1.339202e-06      0.999022          0.000150   0.999021   \n12    0.999996    2.620350e-06      0.998817          0.000246   0.998813   \n13    0.999996    2.620350e-06      0.998817          0.000246   0.998813   \n14    0.999997    1.554112e-06      0.998935          0.000300   0.998932   \n15    0.999999    4.386138e-07      0.999142          0.000195   0.999139   \n16    0.999999    4.386138e-07      0.999142          0.000195   0.999139   \n17    0.999999    4.386138e-07      0.999142          0.000195   0.999139   \n\n    CV Recall Std  \n0        0.000197  \n1        0.000197  \n2        0.000173  \n3        0.000173  \n4        0.000173  \n5        0.000145  \n6        0.000178  \n7        0.000178  \n8        0.000059  \n9        0.000151  \n10       0.000151  \n11       0.000151  \n12       0.000248  \n13       0.000248  \n14       0.000303  \n15       0.000197  \n16       0.000197  \n17       0.000197  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Data Type</th>\n      <th>CV Accuracy</th>\n      <th>CV Accuracy Std</th>\n      <th>CV F1 (Weighted)</th>\n      <th>CV F1 (Weighted) Std</th>\n      <th>CV F1 (Macro)</th>\n      <th>CV F1 (Macro) Std</th>\n      <th>CV ROC AUC</th>\n      <th>CV ROC AUC Std</th>\n      <th>CV Precision</th>\n      <th>CV Precision Std</th>\n      <th>CV Recall</th>\n      <th>CV Recall Std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNN</td>\n      <td>Log</td>\n      <td>0.999228</td>\n      <td>0.000197</td>\n      <td>0.999229</td>\n      <td>0.000197</td>\n      <td>0.998788</td>\n      <td>0.000362</td>\n      <td>0.999999</td>\n      <td>2.545483e-07</td>\n      <td>0.999230</td>\n      <td>0.000196</td>\n      <td>0.999228</td>\n      <td>0.000197</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNN</td>\n      <td>Mixed</td>\n      <td>0.999228</td>\n      <td>0.000197</td>\n      <td>0.999229</td>\n      <td>0.000197</td>\n      <td>0.998788</td>\n      <td>0.000362</td>\n      <td>0.999999</td>\n      <td>2.545483e-07</td>\n      <td>0.999230</td>\n      <td>0.000196</td>\n      <td>0.999228</td>\n      <td>0.000197</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNN</td>\n      <td>Normal</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n      <td>0.998887</td>\n      <td>0.000303</td>\n      <td>0.999915</td>\n      <td>1.029853e-04</td>\n      <td>0.999289</td>\n      <td>0.000172</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM</td>\n      <td>Log</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n      <td>0.998912</td>\n      <td>0.000307</td>\n      <td>0.999997</td>\n      <td>2.016573e-06</td>\n      <td>0.999289</td>\n      <td>0.000172</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBM</td>\n      <td>Mixed</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n      <td>0.998912</td>\n      <td>0.000307</td>\n      <td>0.999997</td>\n      <td>2.016573e-06</td>\n      <td>0.999289</td>\n      <td>0.000172</td>\n      <td>0.999288</td>\n      <td>0.000173</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>Normal</td>\n      <td>0.999377</td>\n      <td>0.000145</td>\n      <td>0.999377</td>\n      <td>0.000145</td>\n      <td>0.999035</td>\n      <td>0.000317</td>\n      <td>0.999996</td>\n      <td>4.776803e-06</td>\n      <td>0.999378</td>\n      <td>0.000145</td>\n      <td>0.999377</td>\n      <td>0.000145</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Logistic Regression</td>\n      <td>Log</td>\n      <td>0.997121</td>\n      <td>0.000178</td>\n      <td>0.997123</td>\n      <td>0.000178</td>\n      <td>0.995376</td>\n      <td>0.000372</td>\n      <td>0.999942</td>\n      <td>1.564464e-05</td>\n      <td>0.997128</td>\n      <td>0.000180</td>\n      <td>0.997121</td>\n      <td>0.000178</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Logistic Regression</td>\n      <td>Mixed</td>\n      <td>0.997121</td>\n      <td>0.000178</td>\n      <td>0.997123</td>\n      <td>0.000178</td>\n      <td>0.995376</td>\n      <td>0.000372</td>\n      <td>0.999942</td>\n      <td>1.564464e-05</td>\n      <td>0.997128</td>\n      <td>0.000180</td>\n      <td>0.997121</td>\n      <td>0.000178</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Logistic Regression</td>\n      <td>Normal</td>\n      <td>0.997211</td>\n      <td>0.000059</td>\n      <td>0.997212</td>\n      <td>0.000061</td>\n      <td>0.995532</td>\n      <td>0.000159</td>\n      <td>0.999936</td>\n      <td>1.952522e-05</td>\n      <td>0.997219</td>\n      <td>0.000065</td>\n      <td>0.997211</td>\n      <td>0.000059</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Random Forest</td>\n      <td>Log</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n      <td>0.998516</td>\n      <td>0.000323</td>\n      <td>0.999997</td>\n      <td>1.354710e-06</td>\n      <td>0.999022</td>\n      <td>0.000150</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Random Forest</td>\n      <td>Mixed</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n      <td>0.998516</td>\n      <td>0.000323</td>\n      <td>0.999997</td>\n      <td>1.354710e-06</td>\n      <td>0.999022</td>\n      <td>0.000150</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Random Forest</td>\n      <td>Normal</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n      <td>0.998516</td>\n      <td>0.000323</td>\n      <td>0.999997</td>\n      <td>1.339202e-06</td>\n      <td>0.999022</td>\n      <td>0.000150</td>\n      <td>0.999021</td>\n      <td>0.000151</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>SVM</td>\n      <td>Log</td>\n      <td>0.998813</td>\n      <td>0.000248</td>\n      <td>0.998814</td>\n      <td>0.000248</td>\n      <td>0.998121</td>\n      <td>0.000533</td>\n      <td>0.999996</td>\n      <td>2.620350e-06</td>\n      <td>0.998817</td>\n      <td>0.000246</td>\n      <td>0.998813</td>\n      <td>0.000248</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>SVM</td>\n      <td>Mixed</td>\n      <td>0.998813</td>\n      <td>0.000248</td>\n      <td>0.998814</td>\n      <td>0.000248</td>\n      <td>0.998121</td>\n      <td>0.000533</td>\n      <td>0.999996</td>\n      <td>2.620350e-06</td>\n      <td>0.998817</td>\n      <td>0.000246</td>\n      <td>0.998813</td>\n      <td>0.000248</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVM</td>\n      <td>Normal</td>\n      <td>0.998932</td>\n      <td>0.000303</td>\n      <td>0.998932</td>\n      <td>0.000302</td>\n      <td>0.998319</td>\n      <td>0.000614</td>\n      <td>0.999997</td>\n      <td>1.554112e-06</td>\n      <td>0.998935</td>\n      <td>0.000300</td>\n      <td>0.998932</td>\n      <td>0.000303</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBoost</td>\n      <td>Log</td>\n      <td>0.999139</td>\n      <td>0.000197</td>\n      <td>0.999140</td>\n      <td>0.000196</td>\n      <td>0.998665</td>\n      <td>0.000369</td>\n      <td>0.999999</td>\n      <td>4.386138e-07</td>\n      <td>0.999142</td>\n      <td>0.000195</td>\n      <td>0.999139</td>\n      <td>0.000197</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBoost</td>\n      <td>Mixed</td>\n      <td>0.999139</td>\n      <td>0.000197</td>\n      <td>0.999140</td>\n      <td>0.000196</td>\n      <td>0.998665</td>\n      <td>0.000369</td>\n      <td>0.999999</td>\n      <td>4.386138e-07</td>\n      <td>0.999142</td>\n      <td>0.000195</td>\n      <td>0.999139</td>\n      <td>0.000197</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBoost</td>\n      <td>Normal</td>\n      <td>0.999139</td>\n      <td>0.000197</td>\n      <td>0.999140</td>\n      <td>0.000196</td>\n      <td>0.998665</td>\n      <td>0.000369</td>\n      <td>0.999999</td>\n      <td>4.386138e-07</td>\n      <td>0.999142</td>\n      <td>0.000195</td>\n      <td>0.999139</td>\n      <td>0.000197</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T18:49:09.711838Z",
     "start_time": "2024-09-09T18:49:09.668957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cv_results_60_20_20"
   ],
   "id": "5598a9e0c4339741",
   "outputs": [
    {
     "data": {
      "text/plain": "                  Model Data Type  CV Accuracy  CV Accuracy Std  \\\n0                   KNN       Log     0.999238         0.000177   \n1                   KNN     Mixed     0.999238         0.000177   \n2                   KNN    Normal     0.999273         0.000170   \n3              LightGBM       Log     0.999238         0.000177   \n4              LightGBM     Mixed     0.999238         0.000177   \n5              LightGBM    Normal     0.999238         0.000139   \n6   Logistic Regression       Log     0.996988         0.001036   \n7   Logistic Regression     Mixed     0.996988         0.001036   \n8   Logistic Regression    Normal     0.997126         0.000907   \n9         Random Forest       Log     0.998996         0.000642   \n10        Random Forest     Mixed     0.998996         0.000642   \n11        Random Forest    Normal     0.998996         0.000642   \n12                  SVM       Log     0.998892         0.000485   \n13                  SVM     Mixed     0.998892         0.000485   \n14                  SVM    Normal     0.998892         0.000543   \n15              XGBoost       Log     0.999377         0.000208   \n16              XGBoost     Mixed     0.999377         0.000208   \n17              XGBoost    Normal     0.999377         0.000208   \n\n    CV F1 (Weighted)  CV F1 (Weighted) Std  CV F1 (Macro)  CV F1 (Macro) Std  \\\n0           0.999238              0.000176       0.998817           0.000248   \n1           0.999238              0.000176       0.998817           0.000248   \n2           0.999273              0.000169       0.998875           0.000279   \n3           0.999238              0.000176       0.998846           0.000288   \n4           0.999238              0.000176       0.998846           0.000288   \n5           0.999238              0.000138       0.998846           0.000224   \n6           0.996989              0.001037       0.995212           0.001698   \n7           0.996989              0.001037       0.995212           0.001698   \n8           0.997127              0.000908       0.995449           0.001450   \n9           0.998996              0.000642       0.998558           0.000988   \n10          0.998996              0.000642       0.998558           0.000988   \n11          0.998996              0.000642       0.998558           0.000988   \n12          0.998892              0.000485       0.998268           0.000776   \n13          0.998892              0.000485       0.998268           0.000776   \n14          0.998892              0.000543       0.998326           0.000850   \n15          0.999377              0.000208       0.999019           0.000334   \n16          0.999377              0.000208       0.999019           0.000334   \n17          0.999377              0.000208       0.999019           0.000334   \n\n    CV ROC AUC  CV ROC AUC Std  CV Precision  CV Precision Std  CV Recall  \\\n0     0.999901        0.000092      0.999240          0.000175   0.999238   \n1     0.999901        0.000092      0.999240          0.000175   0.999238   \n2     0.999853        0.000142      0.999275          0.000168   0.999273   \n3     0.999998        0.000001      0.999239          0.000176   0.999238   \n4     0.999998        0.000001      0.999239          0.000176   0.999238   \n5     0.999998        0.000001      0.999239          0.000139   0.999238   \n6     0.999936        0.000040      0.996994          0.001039   0.996988   \n7     0.999936        0.000040      0.996994          0.001039   0.996988   \n8     0.999936        0.000042      0.997133          0.000910   0.997126   \n9     0.999997        0.000002      0.998998          0.000641   0.998996   \n10    0.999997        0.000002      0.998998          0.000641   0.998996   \n11    0.999997        0.000002      0.998998          0.000641   0.998996   \n12    0.999996        0.000003      0.998894          0.000485   0.998892   \n13    0.999996        0.000003      0.998894          0.000485   0.998892   \n14    0.999997        0.000002      0.998893          0.000543   0.998892   \n15    0.999998        0.000001      0.999378          0.000207   0.999377   \n16    0.999998        0.000001      0.999378          0.000207   0.999377   \n17    0.999998        0.000001      0.999378          0.000207   0.999377   \n\n    CV Recall Std  \n0        0.000177  \n1        0.000177  \n2        0.000170  \n3        0.000177  \n4        0.000177  \n5        0.000139  \n6        0.001036  \n7        0.001036  \n8        0.000907  \n9        0.000642  \n10       0.000642  \n11       0.000642  \n12       0.000485  \n13       0.000485  \n14       0.000543  \n15       0.000208  \n16       0.000208  \n17       0.000208  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Data Type</th>\n      <th>CV Accuracy</th>\n      <th>CV Accuracy Std</th>\n      <th>CV F1 (Weighted)</th>\n      <th>CV F1 (Weighted) Std</th>\n      <th>CV F1 (Macro)</th>\n      <th>CV F1 (Macro) Std</th>\n      <th>CV ROC AUC</th>\n      <th>CV ROC AUC Std</th>\n      <th>CV Precision</th>\n      <th>CV Precision Std</th>\n      <th>CV Recall</th>\n      <th>CV Recall Std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNN</td>\n      <td>Log</td>\n      <td>0.999238</td>\n      <td>0.000177</td>\n      <td>0.999238</td>\n      <td>0.000176</td>\n      <td>0.998817</td>\n      <td>0.000248</td>\n      <td>0.999901</td>\n      <td>0.000092</td>\n      <td>0.999240</td>\n      <td>0.000175</td>\n      <td>0.999238</td>\n      <td>0.000177</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>KNN</td>\n      <td>Mixed</td>\n      <td>0.999238</td>\n      <td>0.000177</td>\n      <td>0.999238</td>\n      <td>0.000176</td>\n      <td>0.998817</td>\n      <td>0.000248</td>\n      <td>0.999901</td>\n      <td>0.000092</td>\n      <td>0.999240</td>\n      <td>0.000175</td>\n      <td>0.999238</td>\n      <td>0.000177</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>KNN</td>\n      <td>Normal</td>\n      <td>0.999273</td>\n      <td>0.000170</td>\n      <td>0.999273</td>\n      <td>0.000169</td>\n      <td>0.998875</td>\n      <td>0.000279</td>\n      <td>0.999853</td>\n      <td>0.000142</td>\n      <td>0.999275</td>\n      <td>0.000168</td>\n      <td>0.999273</td>\n      <td>0.000170</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LightGBM</td>\n      <td>Log</td>\n      <td>0.999238</td>\n      <td>0.000177</td>\n      <td>0.999238</td>\n      <td>0.000176</td>\n      <td>0.998846</td>\n      <td>0.000288</td>\n      <td>0.999998</td>\n      <td>0.000001</td>\n      <td>0.999239</td>\n      <td>0.000176</td>\n      <td>0.999238</td>\n      <td>0.000177</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBM</td>\n      <td>Mixed</td>\n      <td>0.999238</td>\n      <td>0.000177</td>\n      <td>0.999238</td>\n      <td>0.000176</td>\n      <td>0.998846</td>\n      <td>0.000288</td>\n      <td>0.999998</td>\n      <td>0.000001</td>\n      <td>0.999239</td>\n      <td>0.000176</td>\n      <td>0.999238</td>\n      <td>0.000177</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LightGBM</td>\n      <td>Normal</td>\n      <td>0.999238</td>\n      <td>0.000139</td>\n      <td>0.999238</td>\n      <td>0.000138</td>\n      <td>0.998846</td>\n      <td>0.000224</td>\n      <td>0.999998</td>\n      <td>0.000001</td>\n      <td>0.999239</td>\n      <td>0.000139</td>\n      <td>0.999238</td>\n      <td>0.000139</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Logistic Regression</td>\n      <td>Log</td>\n      <td>0.996988</td>\n      <td>0.001036</td>\n      <td>0.996989</td>\n      <td>0.001037</td>\n      <td>0.995212</td>\n      <td>0.001698</td>\n      <td>0.999936</td>\n      <td>0.000040</td>\n      <td>0.996994</td>\n      <td>0.001039</td>\n      <td>0.996988</td>\n      <td>0.001036</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Logistic Regression</td>\n      <td>Mixed</td>\n      <td>0.996988</td>\n      <td>0.001036</td>\n      <td>0.996989</td>\n      <td>0.001037</td>\n      <td>0.995212</td>\n      <td>0.001698</td>\n      <td>0.999936</td>\n      <td>0.000040</td>\n      <td>0.996994</td>\n      <td>0.001039</td>\n      <td>0.996988</td>\n      <td>0.001036</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Logistic Regression</td>\n      <td>Normal</td>\n      <td>0.997126</td>\n      <td>0.000907</td>\n      <td>0.997127</td>\n      <td>0.000908</td>\n      <td>0.995449</td>\n      <td>0.001450</td>\n      <td>0.999936</td>\n      <td>0.000042</td>\n      <td>0.997133</td>\n      <td>0.000910</td>\n      <td>0.997126</td>\n      <td>0.000907</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Random Forest</td>\n      <td>Log</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n      <td>0.998558</td>\n      <td>0.000988</td>\n      <td>0.999997</td>\n      <td>0.000002</td>\n      <td>0.998998</td>\n      <td>0.000641</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Random Forest</td>\n      <td>Mixed</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n      <td>0.998558</td>\n      <td>0.000988</td>\n      <td>0.999997</td>\n      <td>0.000002</td>\n      <td>0.998998</td>\n      <td>0.000641</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Random Forest</td>\n      <td>Normal</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n      <td>0.998558</td>\n      <td>0.000988</td>\n      <td>0.999997</td>\n      <td>0.000002</td>\n      <td>0.998998</td>\n      <td>0.000641</td>\n      <td>0.998996</td>\n      <td>0.000642</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>SVM</td>\n      <td>Log</td>\n      <td>0.998892</td>\n      <td>0.000485</td>\n      <td>0.998892</td>\n      <td>0.000485</td>\n      <td>0.998268</td>\n      <td>0.000776</td>\n      <td>0.999996</td>\n      <td>0.000003</td>\n      <td>0.998894</td>\n      <td>0.000485</td>\n      <td>0.998892</td>\n      <td>0.000485</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>SVM</td>\n      <td>Mixed</td>\n      <td>0.998892</td>\n      <td>0.000485</td>\n      <td>0.998892</td>\n      <td>0.000485</td>\n      <td>0.998268</td>\n      <td>0.000776</td>\n      <td>0.999996</td>\n      <td>0.000003</td>\n      <td>0.998894</td>\n      <td>0.000485</td>\n      <td>0.998892</td>\n      <td>0.000485</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVM</td>\n      <td>Normal</td>\n      <td>0.998892</td>\n      <td>0.000543</td>\n      <td>0.998892</td>\n      <td>0.000543</td>\n      <td>0.998326</td>\n      <td>0.000850</td>\n      <td>0.999997</td>\n      <td>0.000002</td>\n      <td>0.998893</td>\n      <td>0.000543</td>\n      <td>0.998892</td>\n      <td>0.000543</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>XGBoost</td>\n      <td>Log</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n      <td>0.999019</td>\n      <td>0.000334</td>\n      <td>0.999998</td>\n      <td>0.000001</td>\n      <td>0.999378</td>\n      <td>0.000207</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>XGBoost</td>\n      <td>Mixed</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n      <td>0.999019</td>\n      <td>0.000334</td>\n      <td>0.999998</td>\n      <td>0.000001</td>\n      <td>0.999378</td>\n      <td>0.000207</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>XGBoost</td>\n      <td>Normal</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n      <td>0.999019</td>\n      <td>0.000334</td>\n      <td>0.999998</td>\n      <td>0.000001</td>\n      <td>0.999378</td>\n      <td>0.000207</td>\n      <td>0.999377</td>\n      <td>0.000208</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T14:33:51.368143Z",
     "start_time": "2024-09-09T14:33:51.365030Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "6e18e4b027a89990",
   "outputs": [],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
